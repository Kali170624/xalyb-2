import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import cv2

def take_photo(output_dir):
    """Capture a photo using the camera and save it."""
    camera = cv2.VideoCapture(0)
    if not camera.isOpened():
        print("Error: Could not access the camera.")
        return

    print("Taking a photo...")
    ret, frame = camera.read()
    if ret:
        photo_path = os.path.join(output_dir, 'captured_photo.jpg')
        cv2.imwrite(photo_path, frame)
        print(f"Photo saved to {photo_path}")
    else:
        print("Error: Failed to capture photo.")

    camera.release()

def download_html(url, output_dir):
    """Download the HTML content of the URL and save it to a file."""
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, 'html.parser')

    # Modify links to trigger photo capture
    for link in soup.find_all('a', href=True):
        link['href'] = "#"
        link['onclick'] = "alert('Photo captured!');"

    # Save the main HTML file
    html_path = os.path.join(output_dir, 'index.html')
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(soup.prettify())

    print(f"HTML saved to {html_path}")
    return soup

def download_resources(soup, base_url, output_dir):
    """Download resources like images, CSS, and JS linked in the HTML."""
    resource_types = {'img': 'src', 'link': 'href', 'script': 'src'}

    for tag, attr in resource_types.items():
        for element in soup.find_all(tag):
            resource_url = element.get(attr)
            if not resource_url:
                continue

            # Create a full URL and download the resource
            resource_url = urljoin(base_url, resource_url)
            try:
                response = requests.get(resource_url, stream=True)
                response.raise_for_status()

                # Determine local file path
                parsed_url = urlparse(resource_url)
                resource_path = os.path.join(output_dir, parsed_url.path.lstrip('/'))

                # Create directories if needed
                os.makedirs(os.path.dirname(resource_path), exist_ok=True)

                # Save the resource
                with open(resource_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                print(f"Downloaded {resource_url} to {resource_path}")

            except requests.RequestException as e:
                print(f"Failed to download {resource_url}: {e}")

def clone_url(url, output_dir):
    """Clone a webpage by downloading its HTML and linked resources."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    print(f"Cloning {url} into {output_dir}...")

    try:
        soup = download_html(url, output_dir)
        download_resources(soup, url, output_dir)
        take_photo(output_dir)
        print("Cloning complete.")

    except requests.RequestException as e:
        print(f"Error cloning the URL: {e}")

# Example usage
if __name__ == '__main__':
    target_url = "https://example.com"  # Replace with the URL you want to clone
    output_directory = "cloned_site"
    clone_url(target_url, output_directory)
]
